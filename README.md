
# RideWise:Predicting Bike-Sharing Demand Based on Weather and Urban Eventsac

## ðŸ“Œ Project Overview

This project explores how weather, season, and time influence bike rental demand in Washington D.C. This dataset contains both hourly and daily logs, making it useful for understanding short-term trends (like peak commuting hours) as well as long-term seasonal changes.

My main aim in this stage was to prepare a clean, analysis-ready dataset that can later be used for forecasting daily or hourly rental counts.

---

## ðŸ“Š Dataset Description

The original dataset comes from the Capital Bikeshare program and includes two years of usage data (2011â€“2012). This dataset include combined bike usage logs with weather information, so it becomes possible to link temperature, humidity, rain, hour of the day, etc., to rental behavior.

There are two files:

* **day.csv** â€” one row per day
* **hour.csv** â€” one row per hour

Both contain fields like date, season, holiday, working day flag, temperature, humidity, windspeed, and rental counts. Only the hourly file contains the hour column.

I used both files and mearged them to create a richer dataset for modeling. because I wanted to understand the relationship between daily and hourly patterns.

---

## ðŸ“š Dataset Source & Citation

This dataset was originally prepared by **Hadi Fanaee-T** from the University of Porto. Since the authors requested citation in any downstream use, Iâ€™ve included their reference below.

> Fanaee-T, Hadi, and Gama, Joao. (2013).
> *Event labeling combining ensemble detectors and background knowledge.*
> Progress in Artificial Intelligence.
> doi:10.1007/s13748-013-0040-3

Iâ€™ve also linked the Kaggle version for convenience.

Dataset: https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset?select=hour.csv

---

## Preprocessing Steps 

* **Analyzed dataset structure** â€” Inspected null values, duplicates, and overall column distributions.
* **Standardized date format** â€” Converted `dteday` into a consistent `datetime` format across both datasets.
* **Validated logical consistency** â€” Checked conflicting cases (e.g., `holiday = 1` and `workingday = 1`).
* **Merged datasets** â€” Concatenated aligned datasets using `pd.concat()` to create a unified hourlyâ€“daily dataset.
* **Performed post-merge cleanup** â€” Removed duplicates, corrected datatypes, sorted by datetime, and exported the cleaned dataset.

---




